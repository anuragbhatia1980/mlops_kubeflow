{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://cloud.google.com/blog/topics/developers-practitioners/use-vertex-pipelines-build-automl-classification-end-end-workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVX0RV_s8zZ7"
   },
   "source": [
    "# Vertex Pipelines: AutoML Tabular pipelines using google-cloud-pipeline-components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "This notebook shows how to use the components defined in [`google_cloud_pipeline_components`](https://github.com/kubeflow/pipelines/tree/master/components/google-cloud) to build an AutoML Tabular workflow on [Vertex Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines).\n",
    "\n",
    "You'll build a pipeline that looks like this:\n",
    "\n",
    "<a href=\"AutoML_Tabular_DAG.png\" target=\"_blank\"><img src=\"AutoML_Tabular_DAG.png\" width=\"95%\"/></a>\n",
    "\n",
    "### Costs \n",
    "\n",
    "Running this notebook includes billable components of Google Cloud Platform:\n",
    "\n",
    "* Vertex AI Training and Serving\n",
    "* Cloud Storage\n",
    "\n",
    "Learn about [Vertex AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
    "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### Install additional packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IaYsrh0Tc17L"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Google Cloud Notebook product has specific requirements\n",
    "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
    "\n",
    "# Google Cloud Notebook requires dependencies to be installed with '--user'\n",
    "USER_FLAG = \"\"\n",
    "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
    "    USER_FLAG = \"--user\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yxtzwPPNZ-SH"
   },
   "outputs": [],
   "source": [
    "# !pip3 install {USER_FLAG} google-cloud-aiplatform --upgrade\n",
    "# !pip3 install {USER_FLAG} kfp google-cloud-pipeline-components --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhq5zEbGg0XX"
   },
   "source": [
    "### Restart the kernel\n",
    "\n",
    "After you install the additional packages, you need to restart the notebook kernel so it can find the packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GPgNN7eeX1l"
   },
   "source": [
    "Check the versions of the packages you installed.  The KFP SDK version should be >=1.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NN0mULkEeb84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.6.4\n",
      "google_cloud_pipeline_components version: 0.1.3\n"
     ]
    }
   ],
   "source": [
    "!python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "!python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ID = \"kubeflow-1-0-2\"  # <---CHANGE THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "06571eb4063b"
   },
   "source": [
    "#### Timestamp\n",
    "\n",
    "If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a timestamp for each instance session, and append it onto the name of resources you create in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "697568e92bd6"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxhCPW6e46EF"
   },
   "source": [
    "### Create a Cloud Storage bucket as necessary\n",
    "\n",
    "You will need a Cloud Storage bucket for this example.  If you don't have one that you want to use, you can make one now.\n",
    "\n",
    "\n",
    "Set the name of your Cloud Storage bucket below. It must be unique across all\n",
    "Cloud Storage buckets.\n",
    "\n",
    "You may also change the `REGION` variable, which is used for operations\n",
    "throughout the rest of this notebook. Make sure to [choose a region where Vertex AI services are\n",
    "available](https://cloud.google.com/ai-platform-unified/docs/general/locations#available_regions). You may\n",
    "not use a Multi-Regional Storage bucket for training with Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "7IrsFhH2zV5z"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://kubeflow-1-0-2-kubeflowpipelines-default\"  # <---CHANGE THIS\n",
    "REGION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EcIXiGsCePi"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "NIq7R4HZCfIc"
   },
   "outputs": [],
   "source": [
    "# ! gsutil mb -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucvCsknMCims"
   },
   "source": [
    "Finally, validate access to your Cloud Storage bucket by examining its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "vhOb7YnwClBb"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoEqT2Y4DJmf"
   },
   "source": [
    "### Import libraries and define constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYtGjGG45ELJ"
   },
   "source": [
    "Define some constants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "W50CwFNZ0WLp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'gs://kubeflow-1-0-2-kubeflowpipelines-default/pipeline_root/anurag.bhatia'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "\n",
    "USER = \"anurag.bhatia\"  # <---CHANGE THIS\n",
    "PIPELINE_ROOT = \"{}/pipeline_root/{}\".format(BUCKET_NAME, USER)\n",
    "\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IprQaSI25oSk"
   },
   "source": [
    "Do some imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "UFDUBveR5UfJ"
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "import kfp\n",
    "# from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (ClassificationMetrics, Metrics, \n",
    "                        Input, Output,\n",
    "                        component, Model)\n",
    "from kfp.v2.google.client import AIPlatformClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPRb9qg8iGVj"
   },
   "source": [
    "## Define a metrics eval custom component\n",
    "\n",
    "For most of the pipeline steps, we'll be using prebuilt components for Vertex AI services, but we'll define one custom component.  \n",
    "\n",
    "We'll define the new component as a Python-function-based component. \n",
    "Lightweight Python function-based components make it easier to iterate quickly by letting you build your component code as a Python function and generating the component specification for you. \n",
    "\n",
    "Note the `@component` decorator.  When you evaluate the `classif_model_eval` function, the component is compiled to what is essentially a task factory function, that can be used in the the pipeline definition. \n",
    "\n",
    "In addition, a `tables_eval_component.yaml` component definition file will be generated.  The component `yaml` file can be shared & placed under version control, and used later to define a pipeline step. \n",
    "\n",
    "You can also see that the component definition specifies a base image for the component to use (if not specified, the default is Python 3.7), and specifies that the `google-cloud-aiplatform` package should be installed. \n",
    "\n",
    "This component retrieves the classification model evaluation generated by the AutoML Tabular training process, does some parsing, and uses that info to render the ROC curve and confusion matrix for the model. It also uses given metrics threshold information and compares that to the evaluation results to determine whether the model is sufficiently accurate to deploy.\n",
    "\n",
    "(Note that if this had been a regression model, the evaluation information would have a different structure.  So, this custom component is specific to an AutoML Tabular classification task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "0NQrhIsrv3le"
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "           base_image=\"gcr.io/deeplearning-platform-release/tf2-cpu.2-3:latest\",\n",
    "           output_component_file=\"tables_eval_component.yaml\",\n",
    "           packages_to_install=[\"google-cloud-aiplatform\"],\n",
    "          )\n",
    "def classif_model_eval_metrics(\n",
    "                                project: str,\n",
    "                                location: str,  # \"us-central1\",\n",
    "                                api_endpoint: str,  # \"us-central1-aiplatform.googleapis.com\",\n",
    "                                thresholds_dict_str: str,\n",
    "                                model: Input[Model],\n",
    "                                metrics: Output[Metrics],\n",
    "                                metricsc: Output[ClassificationMetrics],\n",
    "                              ) -> NamedTuple(\"Outputs\", [(\"dep_decision\", str)]):  # Return parameter.\n",
    "\n",
    "    \"\"\"This function renders evaluation metrics for an AutoML Tabular classification model.\n",
    "    It retrieves the classification model evaluation generated by the AutoML Tabular training\n",
    "    process, does some parsing, and uses that info to render the ROC curve and confusion matrix\n",
    "    for the model. It also uses given metrics threshold information and compares that to the\n",
    "    evaluation results to determine whether the model is sufficiently accurate to deploy.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    import logging\n",
    "\n",
    "    from google.cloud import aiplatform\n",
    "\n",
    "    # Fetch model eval info\n",
    "    def get_eval_info(client, model_name):\n",
    "        from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "        response = client.list_model_evaluations(parent=model_name)\n",
    "        metrics_list = []\n",
    "        metrics_string_list = []\n",
    "        for evaluation in response:\n",
    "            print(\"model_evaluation\")\n",
    "            print(\" name:\", evaluation.name)\n",
    "            print(\" metrics_schema_uri:\", evaluation.metrics_schema_uri)\n",
    "            metrics = MessageToDict(evaluation._pb.metrics)\n",
    "            for metric in metrics.keys():\n",
    "                logging.info(\"metric: %s, value: %s\", metric, metrics[metric])\n",
    "            metrics_str = json.dumps(metrics)\n",
    "            metrics_list.append(metrics)\n",
    "            metrics_string_list.append(metrics_str)\n",
    "\n",
    "        return (\n",
    "                evaluation.name,\n",
    "                metrics_list,\n",
    "                metrics_string_list,\n",
    "                )\n",
    "\n",
    "    # Use the given metrics threshold(s) to determine whether the model is accurate enough to deploy.\n",
    "    def classification_thresholds_check(metrics_dict, thresholds_dict):\n",
    "        for k, v in thresholds_dict.items():\n",
    "            logging.info(\"k {}, v {}\".format(k, v))\n",
    "            if k in [\"auRoc\", \"auPrc\"]:  # higher is better\n",
    "                if metrics_dict[k] < v:  # if under threshold, don't deploy\n",
    "                    logging.info(\"{} < {}; returning False\".format(metrics_dict[k], v))\n",
    "                    return False\n",
    "        logging.info(\"threshold checks passed.\")\n",
    "        return True\n",
    "\n",
    "    def log_metrics(metrics_list, metricsc):\n",
    "        test_confusion_matrix = metrics_list[0][\"confusionMatrix\"]\n",
    "        logging.info(\"rows: %s\", test_confusion_matrix[\"rows\"])\n",
    "\n",
    "        # log the ROC curve\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        thresholds = []\n",
    "        for item in metrics_list[0][\"confidenceMetrics\"]:\n",
    "            fpr.append(item.get(\"falsePositiveRate\", 0.0))\n",
    "            tpr.append(item.get(\"recall\", 0.0))\n",
    "            thresholds.append(item.get(\"confidenceThreshold\", 0.0))\n",
    "        print(f\"fpr: {fpr}\")\n",
    "        print(f\"tpr: {tpr}\")\n",
    "        print(f\"thresholds: {thresholds}\")\n",
    "        metricsc.log_roc_curve(fpr, tpr, thresholds)\n",
    "\n",
    "        # log the confusion matrix\n",
    "        annotations = []\n",
    "        for item in test_confusion_matrix[\"annotationSpecs\"]:\n",
    "            annotations.append(item[\"displayName\"])\n",
    "        logging.info(\"confusion matrix annotations: %s\", annotations)\n",
    "        metricsc.log_confusion_matrix(\n",
    "                                      annotations,\n",
    "                                      test_confusion_matrix[\"rows\"],\n",
    "                                     )\n",
    "\n",
    "        # log textual metrics info as well\n",
    "        for metric in metrics_list[0].keys():\n",
    "            if metric != \"confidenceMetrics\":\n",
    "                val_string = json.dumps(metrics_list[0][metric])\n",
    "                metrics.log_metric(metric, val_string)\n",
    "        # metrics.metadata[\"model_type\"] = \"AutoML Tabular classification\"\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    aiplatform.init(project=project)\n",
    "    # extract the model resource name from the input Model Artifact\n",
    "    model_resource_path = model.uri.replace(\"aiplatform://v1/\", \"\")\n",
    "    logging.info(\"model path: %s\", model_resource_path)\n",
    "\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\n",
    "    eval_name, metrics_list, metrics_str_list = get_eval_info(\n",
    "                                                              client, \n",
    "                                                              model_resource_path\n",
    "                                                             )\n",
    "    logging.info(\"got evaluation name: %s\", eval_name)\n",
    "    logging.info(\"got metrics list: %s\", metrics_list)\n",
    "    log_metrics(metrics_list, metricsc)\n",
    "\n",
    "    thresholds_dict = json.loads(thresholds_dict_str)\n",
    "    \n",
    "    # Conditional deployment: Whether or not to bless (for inference/deployment) the trained model\n",
    "    deploy = classification_thresholds_check(metrics_list[0], \n",
    "                                             thresholds_dict)\n",
    "    if deploy:\n",
    "        dep_decision = \"true\"\n",
    "    else:\n",
    "        dep_decision = \"false\"\n",
    "    logging.info(\"deployment decision is %s\", dep_decision)\n",
    "\n",
    "    return (dep_decision,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4MjdglUT3Sw"
   },
   "source": [
    "## Define an AutoML Tabular classification pipeline that uses components from `google_cloud_pipeline_components`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf0pugbvftD1"
   },
   "source": [
    "Create a managed tabular dataset from a BQ table and train it using AutoML Tabular Training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpZUV4JupV6P"
   },
   "source": [
    "Generate a model display name to use for the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "hBTRnaOFrZEP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card-fraud1626122557\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "DISPLAY_NAME = \"card-fraud{}\".format(str(int(time.time())))\n",
    "print(DISPLAY_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fjGiImBezMo"
   },
   "source": [
    "Define the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "vEEr62NUftD1"
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=\"automl-card-fraud\",  # Don't make this label/name too long, to avoid error later\n",
    "                  pipeline_root=PIPELINE_ROOT)\n",
    "def pipeline(\n",
    "            bq_source: str = \"bq://kubeflow-1-0-2:credit_card_fraud.train\",\n",
    "            display_name: str = DISPLAY_NAME,\n",
    "            project: str = PROJECT_ID,\n",
    "            gcp_region: str = \"us-central1\",\n",
    "            api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "            thresholds_dict_str: str = '{\"auRoc\": 0.95}',\n",
    "            ):\n",
    "    dataset_create_op = gcc_aip.TabularDatasetCreateOp(\n",
    "                                                       project=project, \n",
    "                                                       display_name=display_name, \n",
    "                                                       bq_source=bq_source\n",
    "                                                       )\n",
    "\n",
    "    training_op = gcc_aip.AutoMLTabularTrainingJobRunOp(\n",
    "                                                        project=project,\n",
    "                                                        display_name=display_name,\n",
    "                                                        optimization_prediction_type=\"classification\",\n",
    "                                                        optimization_objective=\"minimize-log-loss\",  # TODO: only logistic regression algorithm being used?      \n",
    "                                                        budget_milli_node_hours=8000,  # max 8 hours?\n",
    "                                                        column_transformations=[\n",
    "#                                                                                 {\"numeric\": {\"column_name\": \"TransactionID\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"isFraud\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"TransactionDT\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"TransactionAmt\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"card1\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"card2\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"card3\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"C1\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"C2\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"C11\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"C12\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"C13\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"C14\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"D8\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"V45\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"V87\"}},\n",
    "                                                                                {\"numeric\": {\"column_name\": \"V258\"}},\n",
    "                                                                                {\"categorical\": {\"column_name\": \"ProductCD\"}},\n",
    "                                                                                {\"categorical\": {\"column_name\": \"card6\"}},\n",
    "                                                                                {\"categorical\": {\"column_name\": \"emaildomain\"}},\n",
    "#                                                                                 {\"categorical\": {\"column_name\": \"R_emaildomain\"}},\n",
    "                                                                                ],\n",
    "                                                        dataset=dataset_create_op.outputs[\"dataset\"],\n",
    "                                                        target_column=\"isFraud\",  # Whether fraudulent or genuine transaction\n",
    "                                                        )\n",
    "    \n",
    "    model_eval_task = classif_model_eval_metrics(\n",
    "                                                 project,\n",
    "                                                 gcp_region,\n",
    "                                                 api_endpoint,\n",
    "                                                 thresholds_dict_str,\n",
    "                                                 training_op.outputs[\"model\"],\n",
    "                                                )\n",
    "\n",
    "    with dsl.Condition(\n",
    "                       model_eval_task.outputs[\"dep_decision\"] == \"true\",\n",
    "                       name=\"deploy_decision\",\n",
    "                      ):\n",
    "\n",
    "        deploy_op = gcc_aip.ModelDeployOp(\n",
    "                                          model=training_op.outputs[\"model\"],\n",
    "                                          project=project,\n",
    "                                          machine_type=\"n1-standard-4\",\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Hl1iYEKSzjP"
   },
   "source": [
    "## Compile and run the pipeline\n",
    "\n",
    "Now, you're ready to compile the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "ycRc83B6bbfO"
   },
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "                            pipeline_func=pipeline, \n",
    "                            package_path=\"tabular_data_classification_pipeline.json\"  # to be written\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfNuzFswBB4g"
   },
   "source": [
    "The pipeline compilation generates the json job spec file.\n",
    "\n",
    "Next, instantiate an API client object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Hl5Q74_gkW2c"
   },
   "outputs": [],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "api_client = AIPlatformClient(project_id=PROJECT_ID, \n",
    "                              region=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jrn6saiQsPh"
   },
   "source": [
    "Then, you run the defined pipeline like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "R4Ha4FoDQpkd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/automl-card-fraud-20210712205640?project=kubeflow-1-0-2\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = api_client.create_run_from_job_spec(\n",
    "                                                \"tabular_data_classification_pipeline.json\",  # to be used\n",
    "                                                pipeline_root=PIPELINE_ROOT,\n",
    "                                                parameter_values={\"project\": PROJECT_ID, \n",
    "                                                                  \"display_name\": DISPLAY_NAME},\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvBTCP318RKs"
   },
   "source": [
    "Click on the generated link to see your run in the Cloud Console.  \n",
    "\n",
    "<!-- It should look something like this as it is running:\n",
    "\n",
    "<a href=\"https://storage.googleapis.com/amy-jo/images/mp/automl_tabular_classif.png\" target=\"_blank\"><img src=\"https://storage.googleapis.com/amy-jo/images/mp/automl_tabular_classif.png\" width=\"40%\"/></a> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix: (Snapshot from Vertex AI Pipelines Console)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"AutoML_Tabular_Confusion_Matrix.png\" target=\"_blank\"><img src=\"AutoML_Tabular_Confusion_Matrix.png\" width=\"95%\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, ROC curve:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"AutoML_Tabular_SDK_ROC.png\" target=\"_blank\"><img src=\"AutoML_Tabular_SDK_ROC.png\" width=\"95%\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Area Under Curve (AUC): ROC as well as Precision-Recall curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"AutoML_Tabular_AUC_ROC_PR.png\" target=\"_blank\"><img src=\"AutoML_Tabular_AUC_ROC_PR.png\" width=\"95%\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad at all, right? :)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "automl_tabular_classification_beans.ipynb",
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
